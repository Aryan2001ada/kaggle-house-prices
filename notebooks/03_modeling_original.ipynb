{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Modeling - Advanced Regression Techniques\n",
    "\n",
    "This notebook documents our machine learning modeling approach for the Kaggle House Prices competition. We start with a simple baseline model and progressively improve it.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Baseline Model](#baseline)\n",
    "2. [Model Performance Analysis](#performance)\n",
    "3. [Feature Importance](#features)\n",
    "4. [Model Comparison](#comparison)\n",
    "5. [Final Submission](#submission)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline Model Approach {#baseline}\n",
    "\n",
    "### Strategy\n",
    "Our baseline model follows a simple but effective approach:\n",
    "\n",
    "1. **Feature Selection**: Use only numerical features to avoid complex categorical encoding\n",
    "2. **Missing Value Handling**: Fill missing values with median (robust to outliers)\n",
    "3. **Model Choice**: Linear Regression for interpretability and speed\n",
    "4. **No Feature Engineering**: Keep it simple for baseline comparison\n",
    "\n",
    "### Why This Approach?\n",
    "- **Simplicity**: Easy to implement and understand\n",
    "- **Fast**: Quick to train and evaluate\n",
    "- **Interpretable**: Linear coefficients show feature importance\n",
    "- **Baseline**: Establishes minimum performance threshold\n",
    "\n",
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Target variable: SalePrice (range: ${train_df['SalePrice'].min():,} - ${train_df['SalePrice'].max():,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Numerical Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical features\n",
    "numerical_features = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove('Id')  # Remove Id column\n",
    "numerical_features.remove('SalePrice')  # Remove target variable\n",
    "\n",
    "print(f\"Found {len(numerical_features)} numerical features:\")\n",
    "print(\"\\nFeature Categories:\")\n",
    "\n",
    "# Categorize features for better understanding\n",
    "size_features = [f for f in numerical_features if any(x in f.lower() for x in ['sf', 'area', 'frontage'])]\n",
    "room_features = [f for f in numerical_features if any(x in f.lower() for x in ['bath', 'bedroom', 'kitchen', 'room', 'garage'])]\n",
    "quality_features = [f for f in numerical_features if any(x in f.lower() for x in ['qual', 'cond', 'overall'])]\n",
    "time_features = [f for f in numerical_features if any(x in f.lower() for x in ['year', 'yr', 'mo'])]\n",
    "other_features = [f for f in numerical_features if f not in size_features + room_features + quality_features + time_features]\n",
    "\n",
    "print(f\"\\n📏 Size/Area Features ({len(size_features)}): {size_features}\")\n",
    "print(f\"\\n🏠 Room/Bath Features ({len(room_features)}): {room_features}\")\n",
    "print(f\"\\n⭐ Quality Features ({len(quality_features)}): {quality_features}\")\n",
    "print(f\"\\n📅 Time Features ({len(time_features)}): {time_features}\")\n",
    "print(f\"\\n🔧 Other Features ({len(other_features)}): {other_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Analysis and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X_train = train_df[numerical_features].copy()\n",
    "y_train = train_df['SalePrice'].copy()\n",
    "X_test = test_df[numerical_features].copy()\n",
    "\n",
    "# Analyze missing values\n",
    "print(\"Missing Value Analysis:\")\n",
    "train_missing = X_train.isnull().sum()\n",
    "test_missing = X_test.isnull().sum()\n",
    "\n",
    "missing_features = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Train_Missing': [train_missing[f] for f in numerical_features],\n",
    "    'Test_Missing': [test_missing[f] for f in numerical_features],\n",
    "    'Train_Pct': [train_missing[f]/len(X_train)*100 for f in numerical_features],\n",
    "    'Test_Pct': [test_missing[f]/len(X_test)*100 for f in numerical_features]\n",
    "})\n",
    "\n",
    "# Show only features with missing values\n",
    "missing_summary = missing_features[(missing_features['Train_Missing'] > 0) | (missing_features['Test_Missing'] > 0)]\n",
    "print(f\"\\nFeatures with missing values: {len(missing_summary)}\")\n",
    "print(missing_summary.to_string(index=False))\n",
    "\n",
    "# Fill missing values with median\n",
    "print(\"\\nFilling missing values with median...\")\n",
    "for feature in numerical_features:\n",
    "    if X_train[feature].isnull().sum() > 0 or X_test[feature].isnull().sum() > 0:\n",
    "        median_value = X_train[feature].median()\n",
    "        X_train[feature].fillna(median_value, inplace=True)\n",
    "        X_test[feature].fillna(median_value, inplace=True)\n",
    "        print(f\"  {feature}: filled with {median_value}\")\n",
    "\n",
    "print(f\"\\nMissing values after imputation: {X_train.isnull().sum().sum()} (train), {X_test.isnull().sum().sum()} (test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training and Performance Analysis {#performance}\n",
    "\n",
    "### Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model\n",
    "print(\"Training Linear Regression baseline model...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Ensure no negative predictions\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"\\n📊 Baseline Model Performance:\")\n",
    "print(f\"  Training RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"  Training MAE:  ${train_mae:,.2f}\")\n",
    "print(f\"  Training R²:   {train_r2:.4f}\")\n",
    "print(f\"\\n🎯 Test Predictions:\")\n",
    "print(f\"  Range: ${y_test_pred.min():,.0f} - ${y_test_pred.max():,.0f}\")\n",
    "print(f\"  Mean:  ${y_test_pred.mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(lr_model, X_train, y_train, cv=5, \n",
    "                           scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "print(f\"\\n🔄 Cross-Validation Results:\")\n",
    "print(f\"  CV RMSE: ${cv_rmse_scores.mean():,.2f} (±${cv_rmse_scores.std()*2:.2f})\")\n",
    "print(f\"  Individual folds: {[f'${score:,.0f}' for score in cv_rmse_scores]}\")\n",
    "\n",
    "# Check for overfitting\n",
    "if train_rmse < cv_rmse_scores.mean() - cv_rmse_scores.std():\n",
    "    print(\"  ⚠️  Model may be overfitting (training RMSE much lower than CV RMSE)\")\n",
    "else:\n",
    "    print(\"  ✅ Model shows good generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis {#features}\n",
    "\n",
    "### Linear Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Coefficient': lr_model.coef_,\n",
    "    'Abs_Coefficient': np.abs(lr_model.coef_)\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"🏆 Top 15 Most Important Features (by absolute coefficient):\")\n",
    "top_features = feature_importance.head(15)\n",
    "for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "    direction = \"📈\" if row['Coefficient'] > 0 else \"📉\"\n",
    "    print(f\"{i:2d}. {row['Feature']:20} : {direction} ${row['Coefficient']:8,.0f}\")\n",
    "\n",
    "print(f\"\\nModel intercept: ${lr_model.intercept_:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Top 15 most important features\n",
    "top_15 = feature_importance.head(15)\n",
    "colors = ['green' if x > 0 else 'red' for x in top_15['Coefficient']]\n",
    "bars1 = ax1.barh(range(len(top_15)), top_15['Coefficient'], color=colors, alpha=0.7)\n",
    "ax1.set_yticks(range(len(top_15)))\n",
    "ax1.set_yticklabels(top_15['Feature'])\n",
    "ax1.set_xlabel('Coefficient Value')\n",
    "ax1.set_title('Top 15 Feature Coefficients', fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "ax1.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Feature correlation with target\n",
    "correlations = []\n",
    "for feature in numerical_features:\n",
    "    corr = X_train[feature].corr(y_train)\n",
    "    correlations.append(corr)\n",
    "\n",
    "corr_df = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Correlation': correlations,\n",
    "    'Abs_Correlation': np.abs(correlations)\n",
    "})\n",
    "corr_df = corr_df.sort_values('Abs_Correlation', ascending=False)\n",
    "\n",
    "top_corr_15 = corr_df.head(15)\n",
    "colors2 = ['green' if x > 0 else 'red' for x in top_corr_15['Correlation']]\n",
    "bars2 = ax2.barh(range(len(top_corr_15)), top_corr_15['Correlation'], color=colors2, alpha=0.7)\n",
    "ax2.set_yticks(range(len(top_corr_15)))\n",
    "ax2.set_yticklabels(top_corr_15['Feature'])\n",
    "ax2.set_xlabel('Correlation with SalePrice')\n",
    "ax2.set_title('Top 15 Feature Correlations', fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "ax2.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Key Insights:\")\n",
    "print(f\"  • Most important positive feature: {top_features.iloc[0]['Feature']} (+${top_features.iloc[0]['Coefficient']:,.0f})\")\n",
    "most_negative = top_features[top_features['Coefficient'] < 0].iloc[0] if len(top_features[top_features['Coefficient'] < 0]) > 0 else None\n",
    "if most_negative is not None:\n",
    "    print(f\"  • Most important negative feature: {most_negative['Feature']} (${most_negative['Coefficient']:,.0f})\")\n",
    "print(f\"  • Highest correlation: {top_corr_15.iloc[0]['Feature']} ({top_corr_15.iloc[0]['Correlation']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison {#comparison}\n",
    "\n",
    "Let's compare our baseline Linear Regression with a Random Forest model to see if we can improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest for comparison\n",
    "print(\"Training Random Forest model for comparison...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_pred))\n",
    "rf_train_r2 = r2_score(y_train, rf_train_pred)\n",
    "\n",
    "# Cross-validation for Random Forest\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, \n",
    "                              scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_cv_rmse_scores = np.sqrt(-rf_cv_scores)\n",
    "\n",
    "# Model comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest'],\n",
    "    'Train_RMSE': [train_rmse, rf_train_rmse],\n",
    "    'Train_R2': [train_r2, rf_train_r2],\n",
    "    'CV_RMSE_Mean': [cv_rmse_scores.mean(), rf_cv_rmse_scores.mean()],\n",
    "    'CV_RMSE_Std': [cv_rmse_scores.std(), rf_cv_rmse_scores.std()]\n",
    "})\n",
    "\n",
    "print(\"\\n🏁 Model Comparison:\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.2f'))\n",
    "\n",
    "# Determine best model\n",
    "best_model_idx = comparison_df['CV_RMSE_Mean'].idxmin()\n",
    "best_model_name = comparison_df.iloc[best_model_idx]['Model']\n",
    "print(f\"\\n🏆 Best model based on CV RMSE: {best_model_name}\")\n",
    "\n",
    "# Use best model for final predictions\n",
    "if best_model_name == 'Linear Regression':\n",
    "    final_model = lr_model\n",
    "    final_predictions = y_test_pred\n",
    "else:\n",
    "    final_model = rf_model\n",
    "    final_predictions = rf_test_pred\n",
    "\n",
    "print(f\"\\n✅ Using {best_model_name} for final submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Actual vs Predicted - Linear Regression\n",
    "axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, color='blue')\n",
    "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual SalePrice')\n",
    "axes[0, 0].set_ylabel('Predicted SalePrice')\n",
    "axes[0, 0].set_title(f'Linear Regression: Actual vs Predicted\\nR² = {train_r2:.4f}')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals - Linear Regression\n",
    "residuals = y_train - y_train_pred\n",
    "axes[0, 1].scatter(y_train_pred, residuals, alpha=0.6, color='blue')\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Predicted SalePrice')\n",
    "axes[0, 1].set_ylabel('Residuals')\n",
    "axes[0, 1].set_title('Linear Regression: Residual Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Actual vs Predicted - Random Forest\n",
    "axes[1, 0].scatter(y_train, rf_train_pred, alpha=0.6, color='green')\n",
    "axes[1, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual SalePrice')\n",
    "axes[1, 0].set_ylabel('Predicted SalePrice')\n",
    "axes[1, 0].set_title(f'Random Forest: Actual vs Predicted\\nR² = {rf_train_r2:.4f}')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# CV Scores Comparison\n",
    "models = ['Linear Regression', 'Random Forest']\n",
    "cv_means = [cv_rmse_scores.mean(), rf_cv_rmse_scores.mean()]\n",
    "cv_stds = [cv_rmse_scores.std(), rf_cv_rmse_scores.std()]\n",
    "\n",
    "axes[1, 1].bar(models, cv_means, yerr=cv_stds, capsize=5, \n",
    "               color=['blue', 'green'], alpha=0.7)\n",
    "axes[1, 1].set_ylabel('CV RMSE')\n",
    "axes[1, 1].set_title('Cross-Validation RMSE Comparison')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (mean, std) in enumerate(zip(cv_means, cv_stds)):\n",
    "    axes[1, 1].text(i, mean + std + 500, f'${mean:,.0f}', \n",
    "                   ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Submission {#submission}\n",
    "\n",
    "### Create Kaggle Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "print(\"Creating final submission file...\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'SalePrice': final_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('final_submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n📄 Submission file created: final_submission.csv\")\n",
    "print(f\"   Shape: {submission.shape}\")\n",
    "print(f\"   Model used: {best_model_name}\")\n",
    "print(f\"\\n🎯 Prediction Summary:\")\n",
    "print(f\"   Min prediction: ${final_predictions.min():,.0f}\")\n",
    "print(f\"   Max prediction: ${final_predictions.max():,.0f}\")\n",
    "print(f\"   Mean prediction: ${final_predictions.mean():,.0f}\")\n",
    "print(f\"   Median prediction: ${np.median(final_predictions):,.0f}\")\n",
    "\n",
    "print(\"\\n📋 First 10 predictions:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n📋 Last 10 predictions:\")\n",
    "print(submission.tail(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🏠 HOUSE PRICES MODELING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 Dataset:\")\n",
    "print(f\"   • Training samples: {len(train_df):,}\")\n",
    "print(f\"   • Test samples: {len(test_df):,}\")\n",
    "print(f\"   • Features used: {len(numerical_features)} numerical features\")\n",
    "print(f\"   • Target variable: SalePrice (${train_df['SalePrice'].min():,} - ${train_df['SalePrice'].max():,})\")\n",
    "\n",
    "print(f\"\\n🤖 Model Performance:\")\n",
    "print(f\"   • Best model: {best_model_name}\")\n",
    "best_cv_rmse = comparison_df.loc[comparison_df['Model'] == best_model_name, 'CV_RMSE_Mean'].iloc[0]\n",
    "best_cv_std = comparison_df.loc[comparison_df['Model'] == best_model_name, 'CV_RMSE_Std'].iloc[0]\n",
    "print(f\"   • Cross-validation RMSE: ${best_cv_rmse:,.0f} (±${best_cv_std*2:,.0f})\")\n",
    "best_r2 = comparison_df.loc[comparison_df['Model'] == best_model_name, 'Train_R2'].iloc[0]\n",
    "print(f\"   • R² Score: {best_r2:.4f} ({best_r2*100:.1f}% variance explained)\")\n",
    "\n",
    "print(f\"\\n🔍 Key Features:\")\n",
    "print(f\"   • Most important: {top_features.iloc[0]['Feature']} (${top_features.iloc[0]['Coefficient']:+,.0f})\")\n",
    "print(f\"   • Highest correlation: {top_corr_15.iloc[0]['Feature']} ({top_corr_15.iloc[0]['Correlation']:+.3f})\")\n",
    "print(f\"   • Missing values handled: {len(missing_summary)} features imputed with median\")\n",
    "\n",
    "print(f\"\\n📈 Next Steps for Improvement:\")\n",
    "print(f\"   1. Feature Engineering: Create interaction terms, polynomial features\")\n",
    "print(f\"   2. Categorical Features: Encode and include categorical variables\")\n",
    "print(f\"   3. Regularization: Try Ridge, Lasso, ElasticNet regression\")\n",
    "print(f\"   4. Advanced Models: XGBoost, LightGBM, Neural Networks\")\n",
    "print(f\"   5. Ensemble Methods: Combine multiple models\")\n",
    "print(f\"   6. Outlier Treatment: Remove or transform outliers identified in EDA\")\n",
    "print(f\"   7. Target Transformation: Log transform target variable\")\n",
    "\n",
    "print(\"\\n✅ Baseline model complete! Ready for Kaggle submission.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook established our baseline modeling approach for the House Prices competition. We successfully:\n",
    "\n",
    "1. ✅ **Created a simple baseline model** using only numerical features\n",
    "2. ✅ **Achieved reasonable performance** with Linear Regression\n",
    "3. ✅ **Identified key features** that drive house prices\n",
    "4. ✅ **Compared multiple models** to select the best performer\n",
    "5. ✅ **Generated a submission file** ready for Kaggle\n",
    "\n",
    "The baseline establishes a foundation for future improvements through feature engineering, advanced modeling techniques, and ensemble methods.\n",
    "\n",
    "**Files created:**\n",
    "- `final_submission.csv` - Ready for Kaggle submission\n",
    "- This notebook documenting our modeling approach\n",
    "\n",
    "**Next notebook:** `04_advanced_modeling.ipynb` - Feature engineering and advanced techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}